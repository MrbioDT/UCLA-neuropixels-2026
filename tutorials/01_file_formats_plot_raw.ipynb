{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7577d48",
   "metadata": {},
   "source": [
    "## Binary files and raw data\n",
    "\n",
    "SpikeGLX stores raw data in binary files **.bin** accompanied by a text file **.meta** that contains information about the recording. It is useful to understand how data are stored and how to access raw data directly.\n",
    "\n",
    "Binary files are not only used by SpikeGLX, they are common for many imaging and data acquisition applications. They are specially good for cases when you want to record data fast, and without compression, so you can quickly access it.\n",
    "\n",
    "In binary files, data are stored sample by sample, with **16-bit precision**. This makes it possible to record streaming data.\n",
    "\n",
    "<img src=\"bin_stream.png\" width=\"400\">\n",
    "\n",
    "Data from each timepoint are close to each other for all channels so we can reshape these data as **2D array**\n",
    " with shape **NUM_SAMPLES x NUM_CHANNELS** \n",
    "\n",
    "<img src=\"bin_array.png\" width=\"200\">\n",
    "\n",
    "One advantage of binary files is that one can access a data chunk of time quickly **without** loading it into memory which would not be possible for long recordings from many channels.\n",
    "\n",
    "This is called **memory mapping**. The python _numpy_ module has a function to perform memory mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ab79d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded wmm001_250705_rec_d12_g0_t0.imec0.ap.bin with 7299288 samples and 385 channels.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # to map the file and handle data types\n",
    "from pathlib import Path # to find the file and get the number of samples\n",
    "\n",
    "# foldername = Path(r'C:\\Users\\labadmin\\Desktop\\test_data\\SC035_010720_ex_g0\\SC035_010720_ex_g0_imec0')  # path to folder containing the binary file\n",
    "foldername = Path(r'Y:\\SGL_DATA_drive\\wmm001_250705_rec_d12_g0\\wmm001_250705_rec_d12_g0_imec0')\n",
    "# try to find the binary file (has extension .bin)\n",
    "fname = list(foldername.rglob('*.bin'))\n",
    "if not len(fname): # display an error message if the file is not found.\n",
    "    raise(ValueError(f'Could not find the file in folder {foldername}'))\n",
    "else:\n",
    "    fname = fname[0] # the full path to the file\n",
    "\n",
    "dtype = np.dtype('int16')  # for spikeglx records data in int16 format (16 zeros or ones describe each sample)\n",
    "nchannels = 385 # there are 97 channels in the example dataset (385 for a single 1.0 or 2.0 Neuropixels probe)\n",
    "\n",
    "\n",
    "# calculate the sample size from the filesize - using \"fname.stat().st_size\"\n",
    "\n",
    "nsamples = fname.stat().st_size/(nchannels*dtype.itemsize)\n",
    "# use the memmap function to read the file in the correct shape\n",
    "dat = np.memmap(fname,\n",
    "                mode='r', # open in read mode (safe)\n",
    "                dtype = dtype,\n",
    "                shape = (int(nsamples),int(nchannels)))\n",
    "print(f'Loaded {fname.name} with {dat.shape[0]} samples and {dat.shape[1]} channels.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae891d60",
   "metadata": {},
   "source": [
    "SpikeGLX stores the configurations and parameters used in the recording in **.meta** files. \n",
    "\n",
    "These files are simply text files so we can read the number of stored samples directly from these files. \n",
    "\n",
    "For more information about these files look at the [**SpikeGLX documentation**](https://billkarsh.github.io/SpikeGLX/Sgl_help/Metadata_Help.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a12e94f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nSavedChans=385\n",
      "\n",
      "Read the number of channels [385] from the metadata file.\n"
     ]
    }
   ],
   "source": [
    "meta_fname = list(foldername.rglob('*.meta'))[0] # find the metadata file\n",
    "\n",
    "nchannels = None\n",
    "with open(meta_fname,'r') as fd:\n",
    "    for line in fd.readlines():\n",
    "        if 'nSavedChans' in line: # find a line with nSavedChans\n",
    "            print(line)\n",
    "            # split on '=' and get the number\n",
    "            nchannels = int(line.split('=')[-1])\n",
    "print(f'Read the number of channels [{nchannels}] from the metadata file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede163a9",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "SpikeGLX will output *.meta* and *.bin* files for each recording stream. \n",
    "\n",
    "These can be using _numpy_ and _python_ easily and we do not have to load the entire file at once when using memory mapping.\n",
    "\n",
    "---\n",
    "\n",
    "It helps to have a fast drive (like an _NVME_ or _SSD_ drive) to be able to map data quickly.\n",
    "\n",
    "We included a function **load_spikeglx_binary** to parse and load SpikeGLX binary files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2b8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_spikeglx_binary\n",
    "dat,meta = load_spikeglx_binary(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be79bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now plot a subset of the data\n",
    "seconds_to_plot = 1\n",
    "offset = 20\n",
    "sampling_rate = meta['imSampRate']\n",
    "data_chunk = dat[int(offset*sampling_rate):int((offset+seconds_to_plot)*sampling_rate)]\n",
    "\n",
    "import pylab as plt  # for plotting\n",
    "\n",
    "# if on a notebook use the ipympl magic to have interactive figures\n",
    "#%matplotlib ipympl\n",
    "# you can also use \"widget\" of \"qt\"\n",
    "\n",
    "plt.figure(figsize=[8,3])\n",
    "plt.plot(data_chunk[:,0],'k',lw = 0.5)\n",
    "plt.ylabel('Digitized values')\n",
    "plt.xlabel('Samples from offset');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa9715",
   "metadata": {},
   "source": [
    "We don't have the data in the correct units. That is because spikeGLX stores samples in digitized values, those values must be **converted to voltage units** if we want to interpret the amplitude of the signals.\n",
    "\n",
    "The **conversion factor** can be retrieved from the **.meta** file following the formula:\n",
    "\n",
    "    data_volts = data_value * (digitizer_range_volts / digitizer_max_value) / gain\n",
    "\n",
    "The gain depends on the **probe type**.\n",
    "\n",
    " - **NP2** - production (type 2013) have gain **100**.\n",
    " - **NP2a** - development (type 21 and 24) it is **80**\n",
    " - **NP1** have adjustable gain per channel. The value is _imChan0apGain + the fourth col\n",
    " of the imro_ table.\n",
    "\n",
    "[Check the SpikeGLX_Datafile_Tools](https://github.com/jenniferColonell/SpikeGLX_Datafile_Tools) for more scripts and ways to load raw data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00acdb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitizer_range_volts = meta['imAiRangeMax'] # of niAiRangeMax for NI streams or obAiRangeMax for onebox streams\n",
    "digitizer_max_value = meta['imMaxInt'] # or niMaxInt for NI streams or obMaxInt for onebox stream\n",
    "\n",
    "# the gain is fixed for NP2 but variable for 1.0 probes\n",
    "gain = 500\n",
    "if int(meta['imDatPrb_type']) in [21,24]:\n",
    "    gain = 80\n",
    "elif int(meta['imDatPrb_type']) in [2013]:\n",
    "    gain = 100\n",
    "\n",
    "conversion_factor = digitizer_range_volts/digitizer_max_value/gain * 1e6 # convert to microvolt my multiplying by 1e6\n",
    "\n",
    "data_chunk_mvolt = data_chunk*conversion_factor \n",
    "\n",
    "# Plot the data in the corrected units\n",
    "plt.figure(figsize=[8,3])\n",
    "t = offset + np.arange(len(data_chunk_mvolt))/meta['imSampRate']\n",
    "plt.plot(t,data_chunk_mvolt[:,0],color = 'k', lw = 0.5);\n",
    "plt.ylabel('Recorded voltage ($\\mu V$)')\n",
    "plt.xlabel('Samples from offset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3dd803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting multiple channels\n",
    "%matplotlib qt\n",
    "channel_offset = 500\n",
    "channels_to_plot = np.arange(10)\n",
    "plt.figure()\n",
    "plt.plot(t,data_chunk_mvolt[:,channels_to_plot]+np.arange(len(channels_to_plot))*500);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01642744",
   "metadata": {},
   "source": [
    "From the above cell, you can notice that data from individual channels are offset by different values. That is because each channels might have different offsets and one way of solving is filtering. \n",
    "\n",
    "We will apply a bandpass filter to remove frequencies below 300Hz and above 12kHz. There are differnet filters, we'll apply a [butterworth filter](https://en.wikipedia.org/wiki/Butterworth_filter) using _filtfilt_ that will prevent **phase-shifting**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de780b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30001, 385)\n"
     ]
    }
   ],
   "source": [
    "# define a function to perform the filtering (isolate the AP band)\n",
    "def filter_data(X, band = [300,12000],btype = 'band'):\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    Wn = np.array(band) / (meta['imSampRate']/2.) # define the filter band\n",
    "    b, a = butter(3, Wn, btype = btype) # third order butterworth filter\n",
    "    return filtfilt(b,a,X, axis = 0) # use 2 passes\n",
    "\n",
    "fdata_chunk = filter_data(data_chunk_mvolt)\n",
    "\n",
    "print(fdata_chunk.shape)\n",
    "# plotting multiple channels\n",
    "channel_offset = 500\n",
    "channels_to_plot = np.arange(10)\n",
    "plt.figure()\n",
    "plt.plot(t,fdata_chunk[:,channels_to_plot]+np.arange(len(channels_to_plot))*500);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abded03f",
   "metadata": {},
   "source": [
    "Lets look at all channels using ``imshow`` setting _voltage_ as _color_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66a0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = [10,4])\n",
    "plt.imshow(fdata_chunk.T,aspect = 'auto',\n",
    "            clim = [-100,100], # color limits\n",
    "            cmap  = 'RdBu_r',\n",
    "            extent = [offset, offset+seconds_to_plot,0,fdata_chunk.shape[1]])\n",
    "plt.colorbar(shrink=0.3,label='$\\mu$V')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Channel number')\n",
    "plt.xlim([offset+0.2,offset+0.3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f8f6f",
   "metadata": {},
   "source": [
    "In some channels seem to fluctuate at the same time. Those fluctuations make it harder to isolate spiking and can be caused by animal movement, changes in ground voltage, **artifacts**, etc. \n",
    "\n",
    "We can subtract the median voltage at each time point: known as **C**ommon **A**verage **R**eferencing to remove these fluctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493be1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the median of all channels \n",
    "plt.figure(figsize = [8,2])\n",
    "plt.plot(t, np.median(fdata_chunk,axis = 1),color = 'k',lw = 0.1)\n",
    "plt.ylabel('Median across all channels')\n",
    "plt.xlabel('Time (s)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6093466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with CAR correction\n",
    "plt.figure(figsize = [10,4])\n",
    "# remove the median voltage across all channels to perform global CAR\n",
    "car_data = (fdata_chunk.T - np.median(fdata_chunk,axis = 1)).T\n",
    "\n",
    "plt.imshow(car_data.T ,aspect = 'auto',\n",
    "            clim = [-100,100], # color limits\n",
    "            cmap  = 'RdBu_r',\n",
    "            extent = [offset, offset+seconds_to_plot,0,fdata_chunk.shape[1]])\n",
    "plt.colorbar(shrink=0.3,label='$\\mu$V')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Channel number')\n",
    "plt.xlim([offset+0.2,offset+0.3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b70b22",
   "metadata": {},
   "source": [
    "Using ``ipywidgets`` you can build your own interactive visualization to look at data in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ebf9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: ipympl. Using qt instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8e8e60d56c4c398305aab0ff8866f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='offset', max=243.20802545434017), Output()), _dom_clâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampling_rate = meta['imSampRate']\n",
    "duration = 0.1 # how long to visualize\n",
    "\n",
    "# function to filter and apply CAR data, we are using the conversion factor from above\n",
    "def convert_filter_and_car(X):\n",
    "    # use the conversion factor from above\n",
    "    Xf = filter_data(X*conversion_factor)\n",
    "    # remove the median voltage across all channels to perform global CAR\n",
    "    return (Xf.T - np.median(Xf,axis = 1)).T    \n",
    "\n",
    "# this function will load a chunk of data and apply the filters\n",
    "def get_chunk(offset, duration = duration):\n",
    "    chunk = dat[int(offset*sampling_rate):int((offset+duration)*sampling_rate)]\n",
    "    return  convert_filter_and_car(chunk)\n",
    "\n",
    "# use the ipympl magic to have interactivity\n",
    "%matplotlib ipympl\n",
    "# static plot for chunk zero\n",
    "plt.figure(figsize = [10,4])\n",
    "im = plt.imshow(get_chunk(0).T ,aspect = 'auto',\n",
    "            clim = [-100,100], # color limits\n",
    "            cmap  = 'RdBu_r',\n",
    "            extent = [offset, offset+seconds_to_plot,0,fdata_chunk.shape[1]])\n",
    "plt.colorbar(shrink=0.3,label='$\\mu$V')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Channel number');\n",
    "\n",
    "# This function will be ran each time the slider moves, it will load, filter data and pass it to the plot\n",
    "from ipywidgets import interact, FloatSlider\n",
    "@interact(offset = FloatSlider(min=0, max = len(dat-1)/sampling_rate - duration, interval = 0.05))\n",
    "def _plot_interact(offset):\n",
    "    chunk = get_chunk(offset)\n",
    "    im.set_data(chunk.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
